{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#download binary file\n",
    "def download_file_binary(url, file_name, dir_name=None):\n",
    "    req = requests.get(url)\n",
    "    if dir_name != None:\n",
    "        file_name = os.path.join(dir_name, file_name)\n",
    "    binary_file = open(file_name, \"wb\")\n",
    "    binary_file.write(req.content)\n",
    "    binary_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get a table name from a txt file name\n",
    "def get_table_name(file_name):\n",
    "    if file_name.endswith('.txt'):\n",
    "        table_name = file_name.split('.txt')[0]\n",
    "    return table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get a list of fact data from a txt file\n",
    "def read_data_from_txt_file(file_name):\n",
    "    content = []\n",
    "    with open(file_name, 'rt', encoding='utf-8') as f:\n",
    "        content = f.readlines()\n",
    "        content = [x.strip() for x in content] \n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transform data read from txt file to two columns used in sqlite later\n",
    "def transform_datalist(datalist):\n",
    "    data = []\n",
    "    for item in datalist:\n",
    "        temp_list = item.split(\",\")\n",
    "        #column id\n",
    "        i1 = temp_list[0]\n",
    "        #column product_list\n",
    "        i2 = \",\".join(temp_list[1:])\n",
    "        new_item = [i1, i2]\n",
    "        data.append(new_item)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a table and load data into it using the info read from a csv file or a worksheet\n",
    "def load_file_to_database(cursor, table_name, columns=[], data=[]):\n",
    "    #if the table exits, drop the table\n",
    "    cursor.execute('DROP TABLE IF EXISTS {tn}'.format(tn=table_name))\n",
    "    #create table\n",
    "    cursor.execute('CREATE TABLE {tn} ({cn})'.format(tn=table_name,cn=', '.join(columns)))\n",
    "    #load data into table\n",
    "    for row in data:\n",
    "        if row != [' ']:\n",
    "            cursor.execute('INSERT INTO {tn} VALUES{d}'.format(tn=table_name,d=tuple(row)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define variables for sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a sqlite connection\n",
    "conn = sqlite3.connect('market_basket_analytics.db')\n",
    "#create a cursor to execute sql script\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define variables\n",
    "training_dataset_url = \"http://kevincrook.com/utd/market_basket_training.txt\"\n",
    "training_dataset_file_name = \"market_basket_training.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the training dataset\n",
    "download_file_binary(training_dataset_url, training_dataset_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load training dataset into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load training dataset into database\n",
    "table_name = get_table_name(training_dataset_file_name)\n",
    "columns = [\"id\",\"product_list\"]\n",
    "#read data from txt file\n",
    "content = read_data_from_txt_file(training_dataset_file_name)\n",
    "#transform data into two columns which will be used in sqlite\n",
    "data = transform_datalist(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_file_to_database(cursor, table_name, columns, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define variables\n",
    "test_dataset_url = \"http://kevincrook.com/utd/market_basket_test.txt\"\n",
    "test_dataset_file_name = \"market_basket_test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#download the test dataset\n",
    "download_file_binary(test_dataset_url, test_dataset_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load test dataset into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test dataset into database\n",
    "table_name = get_table_name(test_dataset_file_name)\n",
    "columns = [\"id\",\"product_list\"]\n",
    "#read data from txt file\n",
    "content = read_data_from_txt_file(test_dataset_file_name)\n",
    "#transform data into two columns which will be used in sqlite\n",
    "data = transform_datalist(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_file_to_database(cursor, table_name, columns, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1ffb3df36c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate table including frequency information\n",
    "cursor.execute(\"DROP TABLE IF EXISTS frequency\")\n",
    "cursor.execute('CREATE TABLE frequency AS SELECT DISTINCT product_list, count(*) as freq \\\n",
    "                        FROM market_basket_training group by product_list order by product_list')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate all product set and new product set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a set including all products\n",
    "all_product_set = {\"P01\",\"P02\",\"P03\",\"P04\",\"P05\",\"P06\",\"P07\",\"P08\",\"P09\",\"P10\"}\n",
    "#read all combination of products from frequency table\n",
    "cursor.execute('SELECT DISTINCT product_list FROM frequency')\n",
    "freq_list = cursor.fetchall()\n",
    "sold_product_list = []\n",
    "#create a set including all sold products\n",
    "for item in freq_list:\n",
    "    temp_list = item[0].split(\",\")\n",
    "    sold_product_list = sold_product_list + temp_list\n",
    "sold_product_set = set(sold_product_list)\n",
    "#get the set of new products which have not been sold\n",
    "new_product_set = all_product_set - sold_product_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get test data from sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read test data from market_basket_test table\n",
    "cursor.execute(\"SELECT * FROM market_basket_test\")\n",
    "test_list = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run algorithm to generate recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate recommendation list\n",
    "recommendation_list = []\n",
    "\n",
    "#process shopping carts one by one\n",
    "for test in test_list:\n",
    "    \n",
    "    #get test number\n",
    "    test_number = test[0]\n",
    "    \n",
    "    #get the list of products in this cart\n",
    "    if len(test[1]) == 1:\n",
    "        test_product_list = test[1][0]\n",
    "    else:\n",
    "        test_product_list = test[1].split(\",\")\n",
    "        \n",
    "    #remove new product\n",
    "    product_set = set()\n",
    "    for product in test_product_list:\n",
    "        if product not in new_product_set:\n",
    "            product_set.add(product)\n",
    "        \n",
    "    #initial variables\n",
    "    max_freq = 0\n",
    "    add_product = None\n",
    "    \n",
    "    #try to add an old product\n",
    "    for old_product in sold_product_set:\n",
    "        \n",
    "        #if the old_product is in the cart already, move on\n",
    "        if old_product in product_set:\n",
    "            continue\n",
    "        \n",
    "        #add the old_product into the cart, and transform the list of product ot the format used in frequency table\n",
    "        product_set.add(old_product)\n",
    "        product_list = list(product_set)\n",
    "        product_list.sort()\n",
    "        product_list_freq = \",\".join(product_list)  \n",
    "        \n",
    "        #get the frequency that this combination of products appeared in training dataset\n",
    "        cursor.execute(\"SELECT freq FROM frequency where product_list = '{pl}'\".format(pl=product_list_freq))\n",
    "        freq_list = cursor.fetchall()\n",
    "        if freq_list == []:\n",
    "            freq = 0\n",
    "        else:\n",
    "            freq = freq_list[0][0]        \n",
    "        \n",
    "        #compare the frequency with the current max frequency from other processed combinations \n",
    "        if max_freq < max(max_freq, freq):\n",
    "            #replace the max frequency and the product which should be added into the cart\n",
    "            max_freq = freq\n",
    "            add_product = old_product\n",
    "        \n",
    "        #clean the list for next interation\n",
    "        product_set.remove(old_product)\n",
    "    \n",
    "    #append the recommendation for this cart into the recmmendation list\n",
    "    recommendation_list.append((test_number,add_product))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write the recommendation list into a txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the txt file\n",
    "with open('market_basket_recommendations.txt', 'wt', encoding='utf-8') as f:\n",
    "    for item in recommendation_list:\n",
    "        item_list = list(item)\n",
    "        #convert the tuple into the required format\n",
    "        f.write(item_list[0]+','+item_list[1])\n",
    "        #append the end of line character\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('001', 'P09'), ('002', 'P09'), ('003', 'P06'), ('004', 'P09'), ('005', 'P09'), ('006', 'P09'), ('007', 'P09'), ('008', 'P09'), ('009', 'P09'), ('010', 'P09'), ('011', 'P06'), ('012', 'P09'), ('013', 'P09'), ('014', 'P09'), ('015', 'P09'), ('016', 'P09'), ('017', 'P09'), ('018', 'P09'), ('019', 'P06'), ('020', 'P09'), ('021', 'P09'), ('022', 'P06'), ('023', 'P06'), ('024', 'P03'), ('025', 'P09'), ('026', 'P09'), ('027', 'P01'), ('028', 'P01'), ('029', 'P01'), ('030', 'P01'), ('031', 'P01'), ('032', 'P09'), ('033', 'P09'), ('034', 'P01'), ('035', 'P09'), ('036', 'P09'), ('037', 'P01'), ('038', 'P01'), ('039', 'P01'), ('040', 'P09'), ('041', 'P09'), ('042', 'P01'), ('043', 'P01'), ('044', 'P01'), ('045', 'P09'), ('046', 'P09'), ('047', 'P01'), ('048', 'P01'), ('049', 'P01'), ('050', 'P09'), ('051', 'P09'), ('052', 'P09'), ('053', 'P01'), ('054', 'P01'), ('055', 'P01'), ('056', 'P01'), ('057', 'P09'), ('058', 'P09'), ('059', 'P01'), ('060', 'P01'), ('061', 'P01'), ('062', 'P01'), ('063', 'P01'), ('064', 'P09'), ('065', 'P09'), ('066', 'P09'), ('067', 'P01'), ('068', 'P01'), ('069', 'P09'), ('070', 'P01'), ('071', 'P01'), ('072', 'P09'), ('073', 'P01'), ('074', 'P01'), ('075', 'P01'), ('076', 'P01'), ('077', 'P09'), ('078', 'P01'), ('079', 'P01'), ('080', 'P01'), ('081', 'P01'), ('082', 'P01'), ('083', 'P01'), ('084', 'P01'), ('085', 'P09'), ('086', 'P09'), ('087', 'P09'), ('088', 'P09'), ('089', 'P01'), ('090', 'P01'), ('091', 'P01'), ('092', 'P01'), ('093', 'P01'), ('094', 'P09'), ('095', 'P01'), ('096', 'P09'), ('097', 'P01'), ('098', 'P09'), ('099', 'P01'), ('100', 'P09')]\n"
     ]
    }
   ],
   "source": [
    "#print the result\n",
    "print(recommendation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
