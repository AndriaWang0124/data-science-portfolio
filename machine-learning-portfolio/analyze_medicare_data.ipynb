{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import zipfile\n",
    "import openpyxl\n",
    "import sqlite3\n",
    "import re\n",
    "import csv\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create dir\n",
    "def create_dir(dir_name):\n",
    "    os.mkdir(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#download binary file\n",
    "def download_file_binary(url, file_name, dir_name=None):\n",
    "    req = requests.get(url)\n",
    "    if dir_name != None:\n",
    "        file_name = os.path.join(dir_name, file_name)\n",
    "    binary_file = open(file_name, \"wb\")\n",
    "    binary_file.write(req.content)\n",
    "    binary_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#unzip file\n",
    "def unzip_file(file_name, dir_name=None):\n",
    "    if dir_name != None:\n",
    "        file_name = os.path.join(dir_name, file_name)\n",
    "    z = zipfile.ZipFile(file_name, \"r\")\n",
    "    z.extractall(dir_name)\n",
    "    z.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get a list of csv files under a given dir\n",
    "def get_list_csv_files(dir_name):\n",
    "    list_files = os.listdir(dir_name)\n",
    "    list_csv_files = []\n",
    "    for f in list_files:\n",
    "        if f.endswith('csv'):\n",
    "            list_csv_files.append(f)\n",
    "    #ignore the broken csv file\n",
    "    list_csv_files.remove('FY2015_Percent_Change_in_Medicare_Payments.csv')\n",
    "    return list_csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform a given name to be acceptable for sqlLight\n",
    "#t_c_type: 't'- table, 'c' - column\n",
    "def transform_table_and_column_name(name, t_c_type):\n",
    "    name = name.lower()\n",
    "    name = name.replace('%', 'pct')\n",
    "    name = name.replace('/','_')\n",
    "    \n",
    "    regex = re.compile('[\\s-]')\n",
    "    name = regex.sub('_', name)\n",
    "    \n",
    "    regex = re.compile('^[a-z]')\n",
    "    if regex.findall(name) == []:\n",
    "        if t_c_type == 't':\n",
    "            name = 't_' + name\n",
    "        else:\n",
    "            name = 'c_' + name\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get a table name from a csv file name or an excel sheet name\n",
    "def get_table_name(file_name):\n",
    "    if file_name.endswith('.csv'):\n",
    "        table_name = file_name.split('.csv')[0]\n",
    "    else:\n",
    "        table_name = file_name\n",
    "    #replace some illegal characters\n",
    "    table_name = transform_table_and_column_name(table_name, 't')\n",
    "    return table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get a list of table columns from a csv file\n",
    "def get_csv_columns(file_name, dir_name=None):\n",
    "    file = os.path.join(dir_name, file_name)\n",
    "    columns = []\n",
    "    with open(file, 'rt', encoding='cp1252') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for i, rows in enumerate(reader):\n",
    "            if i == 0:\n",
    "                for row in rows:\n",
    "                    #replace some illegal characters, and specify the type for columns\n",
    "                    columns.append(transform_table_and_column_name(row, 'c')+' text')\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get a lit of fact data from a csv file\n",
    "def read_data_from_csv_file(file_name, dir_name=None):\n",
    "    file = os.path.join(dir_name, file_name)    \n",
    "    data = []\n",
    "    with open(file, 'rt', encoding='cp1252') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for i, rows in enumerate(reader):\n",
    "            if i > 0:\n",
    "                data.append(rows)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate a list of table columns from a list of headers in a excel sheet\n",
    "def get_excel_sheet_columns(headers=[]):\n",
    "    columns = []\n",
    "    for header in headers:\n",
    "        columns.append(transform_table_and_column_name(header, 'c')+' text')\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a table and load data into it using the info read from a csv file or a worksheet\n",
    "def load_file_to_database(cursor, table_name, columns=[], data=[]):\n",
    "    #if the table exits, drop the table\n",
    "    cursor.execute('DROP TABLE IF EXISTS {tn}'.format(tn=table_name))\n",
    "    #create table\n",
    "    cursor.execute('CREATE TABLE {tn} ({cn})'.format(tn=table_name,cn=', '.join(columns)))\n",
    "    #load data into table\n",
    "    for row in data:\n",
    "        if row != [' ']:\n",
    "            cursor.execute('INSERT INTO {tn} VALUES{d}'.format(tn=table_name,d=tuple(row)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read header and fact data from an excel sheet\n",
    "def read_excel_sheet(sheet):\n",
    "    i = 1\n",
    "    j = 1\n",
    "    list_sheet = []\n",
    "    while sheet.cell(row = i, column = j).value != None:\n",
    "        list_row = []\n",
    "        while sheet.cell(row = i, column = j).value != None:\n",
    "            list_row.append(sheet.cell(row = i, column = j).value)\n",
    "            j += 1\n",
    "        else:\n",
    "            j = 1\n",
    "        list_sheet.append(list_row)\n",
    "        i += 1\n",
    "    else:\n",
    "        return list_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a worksheet\n",
    "def create_worksheet(workbook, sheet_name, list_header_name=[], data=[]):\n",
    "    worksheet = workbook.create_sheet(sheet_name)\n",
    "    len_column = len(list_header_name)\n",
    "    len_row = len(data)\n",
    "    for j in range(len_column):\n",
    "        worksheet.cell(row=1, column=j+1, value=list_header_name[j])\n",
    "    for i in range(len_row):\n",
    "        for j in range(len_column):\n",
    "            worksheet.cell(row=2+i, column=j+1, value=data[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the stdev class will be used to define an aggregate function in sqllight\n",
    "class stdev:\n",
    "    def __init__(self):\n",
    "        self.mean = 0.0\n",
    "        self.sample_var = 0.0\n",
    "        self.count = 1\n",
    "\n",
    "    def step(self, value):\n",
    "        if value is None:\n",
    "            return\n",
    "        temp_mean = self.mean\n",
    "        self.mean += (value - temp_mean) / self.count\n",
    "        self.sample_var += (value - temp_mean) * (value - self.mean)\n",
    "        self.count += 1\n",
    "\n",
    "    def finalize(self):\n",
    "        if self.count < 3:\n",
    "            return None\n",
    "        return math.sqrt(self.sample_var / (self.count-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define variables for sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a sqlite connection\n",
    "conn = sqlite3.connect('medicare_hospital_compare.db')\n",
    "#create 'stdev' aggreage function\n",
    "conn.create_aggregate(\"stdev\", 1, stdev)\n",
    "#create a cursor to execute sql script\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download zip file and unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define variables \n",
    "gov_zip_file_url = \"https://data.medicare.gov/views/bg9k-emty/files/0a9879e0-3312-4719-a1db-39fd114890f1?content_type=application%2Fzip%3B%20charset%3Dbinary&filename=Hospital_Revised_Flatfiles.zip\"\n",
    "staging_dir_name = \"staging\"\n",
    "gov_zip_file_name = \"Hospital_Revised_Flatfiles.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download zip file and unzip\n",
    "create_dir(staging_dir_name)\n",
    "download_file_binary(gov_zip_file_url, gov_zip_file_name, staging_dir_name)\n",
    "unzip_file(gov_zip_file_name, staging_dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load csv files into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the list of csv files\n",
    "list_csv_files = get_list_csv_files(staging_dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambulatory Surgical Measures-Facility.csv\n",
      "Ambulatory Surgical Measures-National.csv\n",
      "Ambulatory Surgical Measures-State.csv\n",
      "Complications - Hospital.csv\n",
      "Complications - National.csv\n",
      "Complications - State.csv\n",
      "Footnote Crosswalk.csv\n",
      "FY2015_Distribution_of_Net_Change_in_Base_Op_DRG_Payment_Amt.csv\n",
      "FY2015_Net_Change_in_Base_Op_DRG_Payment_Amt.csv\n",
      "FY2015_Value_Based_Incentive_Payment_Amount.csv\n",
      "GLOBAL_April2017_09March2017.csv\n",
      "HCAHPS - Hospital.csv\n",
      "HCAHPS - National.csv\n",
      "HCAHPS - State.csv\n",
      "Healthcare Associated Infections - Hospital.csv\n",
      "Healthcare Associated Infections - National.csv\n",
      "Healthcare Associated Infections - State.csv\n",
      "Hospital General Information.csv\n",
      "HOSPITAL_QUARTERLY_HAC_DOMAIN_HOSPITAL.csv\n",
      "HOSPITAL_QUARTERLY_IPFQR_MEASURES_HOSPITAL.csv\n",
      "HOSPITAL_QUARTERLY_IPFQR_MEASURES_NATIONAL.csv\n",
      "HOSPITAL_QUARTERLY_IPFQR_MEASURES_STATE.csv\n",
      "HOSPITAL_QUARTERLY_MSPB_6_DECIMALS.csv\n",
      "HOSPITAL_QUARTERLY_QUALITYMEASURE_PCH_HCAHPS_HOSPITAL.csv\n",
      "HOSPITAL_QUARTERLY_QUALITYMEASURE_PCH_HCAHPS_NATIONAL.csv\n",
      "HOSPITAL_QUARTERLY_QUALITYMEASURE_PCH_HCAHPS_STATE.csv\n",
      "HOSPITAL_QUARTERLY_QUALITYMEASURE_PCH_HOSPITAL.csv\n",
      "HOSPITAL_QUARTERLY_QUALITYMEASURE_PCH_OCM_HOSPITAL.csv\n",
      "hvbp_ami_11_14_2016.csv\n",
      "hvbp_clinical_care_outcomes_11_10_2016.csv\n",
      "hvbp_efficiency_11_10_2016.csv\n",
      "hvbp_hcahps_11_10_2016.csv\n",
      "hvbp_imm2_11_10_2016.csv\n",
      "hvbp_pc_11_10_2016.csv\n",
      "hvbp_safety_11_10_2016.csv\n",
      "hvbp_tps_11_10_2016.csv\n",
      "Measure Dates.csv\n",
      "Medicare Hospital Spending by Claim.csv\n",
      "Medicare Hospital Spending per Patient - Hospital.csv\n",
      "Medicare Hospital Spending per Patient - National.csv\n",
      "Medicare Hospital Spending per Patient - State.csv\n",
      "MORT_READM_April2017.csv\n",
      "Outpatient Imaging Efficiency - Hospital.csv\n",
      "Outpatient Imaging Efficiency - National.csv\n",
      "Outpatient Imaging Efficiency - State.csv\n",
      "Outpatient Procedures - Volume.csv\n",
      "Payment - National.csv\n",
      "Payment - State.csv\n",
      "Payment and Value of Care - Hospital.csv\n",
      "PSI_April2017.csv\n",
      "READMISSION REDUCTION.csv\n",
      "Readmissions and Deaths - Hospital.csv\n",
      "Readmissions and Deaths - National.csv\n",
      "Readmissions and Deaths - State.csv\n",
      "Structural Measures - Hospital.csv\n",
      "Timely and Effective Care - Hospital.csv\n",
      "Timely and Effective Care - National.csv\n",
      "Timely and Effective Care - State.csv\n",
      "Value of Care - National.csv\n",
      "VA_HBIPS_December2016_CMS_Submission.csv\n",
      "VA_IPSHEP_Apr2017CMS_09MAR17.csv\n"
     ]
    }
   ],
   "source": [
    "#laod all csv files into database\n",
    "for f in list_csv_files:\n",
    "    print(f)\n",
    "    table_name = get_table_name(f)\n",
    "    columns = get_csv_columns(f, staging_dir_name)\n",
    "    data = read_data_from_csv_file(f, staging_dir_name)\n",
    "    load_file_to_database(cursor, table_name, columns, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download the excel file and load it to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define variables\n",
    "inhouse_excel_file_url = \"http://kevincrook.com/utd/hospital_ranking_focus_states.xlsx\"\n",
    "inhouse_excel_file_name = \"hospital_ranking_focus_states.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#download the inhouse excel file\n",
    "download_file_binary(inhouse_excel_file_url, inhouse_excel_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read inhouse excel file book \n",
    "workbook = openpyxl.load_workbook(inhouse_excel_file_name)\n",
    "list_sheet_names = workbook.get_sheet_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read inhouse excel file sheets and load into database\n",
    "for sheet_name in list_sheet_names:\n",
    "    #read sheet\n",
    "    list_sheet_contents = []\n",
    "    sheet = workbook.get_sheet_by_name(sheet_name)\n",
    "    list_sheet_contents = read_excel_sheet(sheet)    \n",
    "    #load sheet into database    \n",
    "    table_name = get_table_name(sheet_name)\n",
    "    columns = get_excel_sheet_columns(list_sheet_contents[0])\n",
    "    data = list_sheet_contents[1:]\n",
    "    load_file_to_database(cursor, table_name, columns, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the hospital ranking excel workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create the hospital ranking workbook \n",
    "wb_ranking = openpyxl.Workbook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute query for nationwide hospital ranking\n",
    "cursor.execute('SELECT T.provider_id, LJT.hospital_name, LJT.city, LJT.state, LJT.county_name \\\n",
    "    FROM hospital_national_ranking T LEFT JOIN hospital_general_information LJT ON T.provider_id = LJT.provider_id \\\n",
    "    WHERE CAST(T.ranking AS INT) <= 100 ORDER BY T.ranking')\n",
    "list_national_ranking = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the result to excel sheet\n",
    "sheet_name = 'Nationwide'\n",
    "list_header_name = ['Provider ID', 'Hospital Name', 'City', 'State', 'County']\n",
    "create_worksheet(wb_ranking, sheet_name, list_header_name, list_national_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute query for the list of focus state\n",
    "cursor.execute('SELECT state_name, state_abbreviation FROM focus_states ORDER BY state_name')\n",
    "list_focus_states = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute query for hospital ranking in each focus state and save the results to excel sheets\n",
    "for state in list_focus_states:\n",
    "    state_name = state[0]\n",
    "    state_abbr = state[1]\n",
    "    list_state_ranking = []\n",
    "    \n",
    "    #execute the query\n",
    "    cursor.execute('SELECT T.provider_id, LJT.hospital_name, LJT.city, LJT.state, LJT.county_name \\\n",
    "    FROM hospital_national_ranking T LEFT JOIN hospital_general_information LJT ON T.provider_id = LJT.provider_id \\\n",
    "    WHERE LJT.state == \"{st}\" ORDER BY T.ranking'.format(st=state_abbr))\n",
    "    all_rows = cursor.fetchall()\n",
    "    #only take the top 100 records\n",
    "    list_state_ranking = all_rows[:100]\n",
    "    \n",
    "    #save the result to excel sheet    \n",
    "    sheet_name = state_name\n",
    "    create_worksheet(wb_ranking, sheet_name, list_header_name, list_state_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the hospital_ranking workbook\n",
    "wb_ranking.remove_sheet(wb_ranking.get_sheet_by_name(\"Sheet\"))\n",
    "wb_ranking.save(\"hospital_ranking.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the measure statistics excel workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create the measure statistics workbook \n",
    "wb_stat = openpyxl.Workbook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute query for nationwide statistics. STDEV is a manually added aggreage function\n",
    "cursor.execute('SELECT measure_id, measure_name, MIN(CAST(score AS FLOAT)),MAX(CAST(score AS FLOAT)), \\\n",
    "    ROUND(AVG(CAST(score AS FLOAT)),4), ROUND(STDEV(CAST(score AS FLOAT)),4) \\\n",
    "    FROM timely_and_effective_care___hospital WHERE score==score+0 \\\n",
    "    GROUP BY measure_id, measure_name ORDER BY measure_id')\n",
    "list_nationawide_statistics = cursor.fetchall() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the result to excel sheet \n",
    "sheet_name = 'Nationwide'\n",
    "list_header_name = ['Measure ID', 'Measure Name', 'Minimum', 'Maximum', 'Average', 'Standard Deviation']\n",
    "create_worksheet(wb_stat, sheet_name, list_header_name, list_nationawide_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#execute query for measure statistics in each focus state and save results to excel sheets\n",
    "for state in list_focus_states:\n",
    "    state_name = state[0]\n",
    "    state_abbr = state[1]\n",
    "    list_state_statistics = []    \n",
    "    \n",
    "    #'WHERE score==score+0' will exclude the records having non-numaric score'\n",
    "    cursor.execute('SELECT measure_id, measure_name, MIN(CAST(score AS FLOAT)),MAX(CAST(score AS FLOAT)), \\\n",
    "        ROUND(AVG(CAST(score AS FLOAT)),4), ROUND(STDEV(CAST(score AS FLOAT)),4) \\\n",
    "        FROM timely_and_effective_care___hospital WHERE score==score+0 and state == \"{st}\"\\\n",
    "        GROUP BY measure_id, measure_name ORDER BY measure_id'.format(st=state_abbr))\n",
    "    list_state_statistics = cursor.fetchall()\n",
    "    \n",
    "    #save the result to excel sheet\n",
    "    sheet_name = state_name\n",
    "    create_worksheet(wb_stat, sheet_name, list_header_name, list_state_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the measure statistics workbook\n",
    "wb_stat.remove_sheet(wb_stat.get_sheet_by_name(\"Sheet\"))\n",
    "wb_stat.save(\"measure_statistics.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
